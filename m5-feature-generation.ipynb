{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle M5 Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "Pre-training split:\n",
    "- product not yet released (leading zeros)\n",
    "- product no longer sold (trailing zeros)\n",
    "- lags and rolling lags (mean, std)\n",
    "- day, week, month, year, week of month, day of week, weekend\n",
    "- events\n",
    "- price change (week, month, year)\n",
    "- price min, max, std, mean, nunique\n",
    "- snap purchases allowed\n",
    "- release?\n",
    "- snap state?\n",
    "- out of stock? sales volatility x recent sales\n",
    "- features that are hard to learn if scale changes across products e.g. implied changes over time\n",
    "\n",
    "Post-training split\n",
    "- id, cat, dep mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs():\n",
    "    calendar_df = pd.read_csv(\"data/calendar.csv\", low_memory=False)\n",
    "    sales_df = pd.read_csv(\"data/sales_train_validation.csv\", low_memory=False)\n",
    "    prices_df = pd.read_csv(\"data/sell_prices.csv\", low_memory=False)\n",
    "\n",
    "    return (\n",
    "        sales_df\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"d_{1914+i}\": np.nan for i in range(56)\n",
    "            }\n",
    "        )\n",
    "        .melt(\n",
    "            id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "            var_name=\"d\",\n",
    "            value_name=\"sales\"\n",
    "        )\n",
    "        .merge(calendar_df, on=[\"d\"])\n",
    "        .merge(prices_df, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n",
    "        .assign(total_sales=lambda x: x[\"sales\"] * x[\"sell_price\"])\n",
    "        .assign(day=lambda x: x[\"d\"].str.slice(start=2).astype(int))\n",
    "        .assign(date=lambda x: pd.to_datetime(x[\"date\"]))\n",
    "        .assign(dayofyear=lambda x: x[\"date\"].dt.dayofyear)\n",
    "        .assign(dayofmonth=lambda x: x[\"date\"].dt.day)\n",
    "        .drop(columns=[\"d\", \"wm_yr_wk\", \"weekday\"])\n",
    "    )\n",
    "\n",
    "def downcast_variables(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(id=lambda x: x[\"id\"].astype(\"category\"))\n",
    "        .assign(item_id=lambda x: x[\"item_id\"].astype(\"category\"))\n",
    "        .assign(dept_id=lambda x: x[\"dept_id\"].astype(\"category\"))\n",
    "        .assign(cat_id=lambda x: x[\"cat_id\"].astype(\"category\"))\n",
    "        .assign(store_id=lambda x: x[\"store_id\"].astype(\"category\"))\n",
    "        .assign(state_id=lambda x: x[\"state_id\"].astype(\"category\"))\n",
    "        .assign(event_name_1=lambda x: x[\"event_name_1\"].astype(\"category\"))\n",
    "        .assign(event_type_1=lambda x: x[\"event_type_1\"].astype(\"category\"))\n",
    "        .assign(event_name_2=lambda x: x[\"event_name_2\"].astype(\"category\"))\n",
    "        .assign(event_type_2=lambda x: x[\"event_type_2\"].astype(\"category\"))\n",
    "        .assign(sales=lambda x: pd.to_numeric(x[\"sales\"], downcast=\"unsigned\"))\n",
    "        .assign(wday=lambda x: pd.to_numeric(x[\"wday\"], downcast=\"unsigned\"))\n",
    "        .assign(month=lambda x: pd.to_numeric(x[\"month\"], downcast=\"unsigned\"))\n",
    "        .assign(year=lambda x: pd.to_numeric(x[\"year\"], downcast=\"unsigned\"))\n",
    "        .assign(snap_CA=lambda x: pd.to_numeric(x[\"snap_CA\"], downcast=\"unsigned\"))\n",
    "        .assign(snap_TX=lambda x: pd.to_numeric(x[\"snap_TX\"], downcast=\"unsigned\"))\n",
    "        .assign(snap_WI=lambda x: pd.to_numeric(x[\"snap_WI\"], downcast=\"unsigned\"))\n",
    "        .assign(day=lambda x: pd.to_numeric(x[\"day\"], downcast=\"unsigned\"))\n",
    "        .assign(dayofyear=lambda x: pd.to_numeric(x[\"dayofyear\"], downcast=\"unsigned\"))\n",
    "        .assign(dayofmonth=lambda x: pd.to_numeric(x[\"dayofmonth\"], downcast=\"unsigned\"))\n",
    "        .assign(sell_price=lambda x: pd.to_numeric(x[\"sell_price\"], downcast=\"float\"))\n",
    "        .assign(total_sales=lambda x: pd.to_numeric(x[\"total_sales\"], downcast=\"float\"))\n",
    "        .sort_values(by=[\"id\", \"date\"], ascending=True)\n",
    "    )\n",
    "\n",
    "def write_dist_inputs(df, groups, path, prefix):\n",
    "    for group, group_df in tqdm(df.groupby(groups)):\n",
    "        group_df.to_parquet(path + prefix + \"_\".join(group) + \".parquet\")\n",
    "        \n",
    "def sales_rolling_transform(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"sales_lag{lag}_win{win}\": (\n",
    "                    df\n",
    "                    .groupby(\"id\")\n",
    "                    .rolling(win, min_periods=1)[f\"sales_lag{lag}\"].mean()\n",
    "                    .astype(\"float32\")\n",
    "                    .values\n",
    "                )\n",
    "                for lag in range(1,56+1)\n",
    "                for win in (7, 30, 121, 365)\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def price_rolling_transform(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"sell_price_lag{lag}_win{win}\": (\n",
    "                    df\n",
    "                    .groupby(\"id\")\n",
    "                    .rolling(win, min_periods=1)[f\"sell_price_lag{lag}\"].mean()\n",
    "                    .astype(\"float32\")\n",
    "                    .values\n",
    "                )\n",
    "                for lag in (0, 7, 14, 28)\n",
    "                for win in (7, 30, 121, 365)\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def sales_lags(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"sales_lag{lag}\": df.groupby(\"id\")[\"sales\"].shift(lag).astype(\"float32\")\n",
    "                for lag in range(1,56+1)\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def price_lags(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"sell_price_lag{lag}\": df.groupby(\"id\")[\"sell_price\"].shift(lag).astype(\"float32\")\n",
    "                for lag in (0, 7, 14, 28)\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def change_in_sales(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"change_in_sales_lag{lag+1}_w_o_w\": df[f\"sales_lag{lag+1}_win7\"] - df[f\"sales_lag{lag+1+7}_win7\"]\n",
    "                for lag in range(28)\n",
    "            }\n",
    "        )\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"change_in_sales_lag{lag+1}_w_o_m\": df[f\"sales_lag{lag+1}_win7\"] - df[f\"sales_lag{lag+1+28}_win7\"]\n",
    "                for lag in range(28)\n",
    "            }\n",
    "        )\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"change_in_sales_lag{lag+1}_m_o_m\": df[f\"sales_lag{lag+1}_win30\"] - df[f\"sales_lag{lag+1+28}_win30\"]\n",
    "                for lag in range(28)\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def change_in_prices(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            **{\n",
    "                \"change_in_price_w_o_w\": df[\"sell_price_lag0_win7\"] / df[\"sell_price_lag7_win7\"],\n",
    "                \"change_in_price_w_o_m\": df[\"sell_price_lag0_win7\"] / df[\"sell_price_lag28_win7\"],\n",
    "                \"change_in_price_m_o_m\": df[\"sell_price_lag0_win30\"] / df[\"sell_price_lag28_win30\"],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def snap_eligible(df):\n",
    "    df[\"snap\"] = np.where(\n",
    "        df[\"state_id\"] == \"CA\",\n",
    "        df[\"snap_CA\"],\n",
    "        np.where(df[\"state_id\"] == \"TX\", df[\"snap_TX\"], df[\"snap_WI\"])\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def train_eval_test_assignment(df, splits=(0.8, 0.1, 0.1)):\n",
    "    assert sum(splits) == 1, \"The sum of the splits must equal 1\"\n",
    "    assert len(splits) == 3, \"Three split values must be provided\"\n",
    "    return np.random.choice([\"train\", \"eval\", \"test\"], size=len(df), p=splits)\n",
    "\n",
    "def random_group_assignment(df):\n",
    "    df[\"group\"] = np.where(\n",
    "        df.day >= 1914,\n",
    "        \"forecast\",\n",
    "        train_eval_test_assignment(df, splits=(0.8, 0.1, 0.1))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def encode_event_null(df):\n",
    "    for col in (\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"):\n",
    "        df[col] = df[col].cat.add_categories(\"NA\").fillna(\"NA\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(filename):\n",
    "    (\n",
    "        pd.read_parquet(filename)\n",
    "        .pipe(encode_event_null)\n",
    "        .pipe(random_group_assignment)\n",
    "        .pipe(sales_lags)\n",
    "        .pipe(sales_rolling_transform)\n",
    "        .pipe(price_lags)\n",
    "        .pipe(price_rolling_transform)\n",
    "        .pipe(change_in_sales)\n",
    "        .pipe(change_in_prices)\n",
    "        .pipe(snap_eligible)\n",
    "        .to_parquet(filename)\n",
    "    )\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    generate_inputs()\n",
    "    .pipe(downcast_variables)\n",
    "    .pipe(write_dist_inputs, groups=[\"cat_id\", \"store_id\"], path=\"features/\", prefix=\"inputs_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [2:33:57<00:00, 307.92s/it]   \n"
     ]
    }
   ],
   "source": [
    "with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "    files = glob.glob(\"features/inputs_*_*.parquet\")\n",
    "    with tqdm(total=len(files)) as pbar:\n",
    "        for _ in pool.imap_unordered(data_pipeline, (filename for filename in files)):\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.read_parquet(\"features/inputs_*_*.parquet\").to_parquet(\"features/inputs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-m5",
   "language": "python",
   "name": "conda-env-kaggle-m5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
