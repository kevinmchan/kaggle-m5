{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle M5 Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pool(df, trial, subsample=True):\n",
    "    if subsample:\n",
    "        sample_df = df.sample(frac=trial[\"subsample\"])\n",
    "    else:\n",
    "        sample_df = df\n",
    "    return Pool(\n",
    "        data=sample_df[trial[\"features\"]], \n",
    "        label=sample_df[\"sales\"],\n",
    "        weight=sample_df[\"sell_price\"],\n",
    "        cat_features=trial[\"cat_features\"],\n",
    "    )\n",
    "\n",
    "def generate_training_pools(train_splits, trial, subsample=True):\n",
    "    return [generate_pool(train_splits[group], trial, subsample) for group in (\"train\", \"eval\", \"test\")]\n",
    "\n",
    "def score_data(df, model, trail):\n",
    "    pool = generate_pool(df, trail, subsample=False)\n",
    "    df[\"prediction\"] = model.predict(pool)\n",
    "    df[\"total_sales_prediction\"] = df[\"prediction\"] * df[\"sell_price\"]\n",
    "    df[\"error\"] = df[\"total_sales_prediction\"] - df[\"total_sales\"]\n",
    "    df[\"abs_error\"] = abs(df[\"total_sales_prediction\"] - df[\"total_sales\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    input_df = pd.read_parquet(filename)\n",
    "    for col in (\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"):\n",
    "        input_df[col] = input_df[col].cat.add_categories(\"NA\").fillna(\"NA\")\n",
    "    train_splits = {group: input_df.query(\"group == @group\") for group in (\"train\", \"eval\", \"test\", \"forecast\")}\n",
    "    return train_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = load_data(\"features/inputs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"train\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "- are there missing rows in the time series from when the product was not sold?\n",
    "- are there missing or zero-valued prices?\n",
    "- is the data zero-inflated?\n",
    "- how to incorporate events?\n",
    "- how to incorporate sales trends?\n",
    "- how to incorporate pricing trends?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"train\"].sample(frac=0.01).describe(percentiles=[0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_splits[\"train\"].sample(frac=0.01).select_dtypes(exclude=[\"number\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First entry in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(\n",
    "    train_splits[\"train\"].groupby(\"id\")[\"day\"].min()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"train\"].groupby(\"id\")[\"day\"].min().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental model builds\n",
    "\n",
    "Model 1:\n",
    "+ dates: dayofyear, year, month, dayofmonth, wday\n",
    "+ product: dept, cat, item\n",
    "+ store: store, state\n",
    "\n",
    "Model 2:\n",
    "+ rolling averages (7, 30, 121, 365 days; lagged by 1 day)\n",
    "\n",
    "Model 3:\n",
    "+ rolling averages (7, 30, 121, 365 days; lagged by 1, 7, 14, 28 days)\n",
    "\n",
    "Model 4:\n",
    "+ lag sales (1, 7, 14, 28 days)\n",
    "\n",
    "Model 5:\n",
    "+ weekday as categorical\n",
    "\n",
    "Model 6:\n",
    "+ month as categorical (no improvement)\n",
    "\n",
    "Model 7:\n",
    "+ change in sales (no improvement)\n",
    "\n",
    "Model 8:\n",
    "+ change in prices (no improvement)\n",
    "\n",
    "Model 9:\n",
    "+ snap eligible\n",
    "\n",
    "Model 10:\n",
    "+ test without lag features past 28 days\n",
    "\n",
    "Model 11:\n",
    "+ single store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data/experiments.pickle'):\n",
    "    with open('data/experiments.pickle', 'rb') as handle:\n",
    "        experiments = pickle.load(handle)\n",
    "else:\n",
    "    experiments = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag=28\n",
    "trial = {\n",
    "    \"features\": (\n",
    "        [\"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\", \"item_id\", \"store_id\", \"sell_price\", f\"sales_lag{lag}\"]\n",
    "        + [f\"sales_lag{lag}_win{window}\" for window in (30, 121, 365)]\n",
    "    ),\n",
    "    \"cat_features\": [\n",
    "        \"dept_id\", \"item_id\", \"store_id\",\n",
    "    ],\n",
    "    \"model_params\": dict(\n",
    "        iterations=100,\n",
    "        boosting_type=\"Plain\",\n",
    "        loss_function=\"Tweedie:variance_power=1.1\",\n",
    "    ),\n",
    "    \"fit_params\": dict(\n",
    "        use_best_model=True,\n",
    "        plot=True,\n",
    "        metric_period=50,\n",
    "    ),\n",
    "    \"subsample\": 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool, eval_pool, test_pool = generate_training_pools(train_splits, trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(**trial[\"model_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_pool, eval_set=eval_pool, **trial[\"fit_params\"])\n",
    "\n",
    "current_time = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "trial[\"model_name\"] = f\"data/model_{current_time}.cbm\"\n",
    "model.save_model(\"data/model.cbm\", pool=train_pool)\n",
    "model.save_model(trial[\"model_name\"], pool=train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"eval\"] = score_data(train_splits[\"eval\"], model, trial)\n",
    "score = lambda x: r2_score(x[\"sales\"], x[\"prediction\"], sample_weight=x[\"sell_price\"])\n",
    "trial[\"eval_score\"] = score(train_splits[\"eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Eval score: {trial['eval_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sample = train_splits[\"eval\"].sample(frac=0.01)\n",
    "shap_values = model.get_feature_importance(generate_pool(shap_sample, trial, subsample=False), type=\"ShapValues\")\n",
    "expected_value = shap_values[0,-1]\n",
    "shap_values = shap_values[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, shap_sample[trial[\"features\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, shap_sample[trial[\"features\"]], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = input(\"Enter trial name: \")\n",
    "experiments[trial_name] = trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/experiments.pickle', 'wb') as handle:\n",
    "    pickle.dump(experiments, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"total_sales\",\n",
    "    hue=\"year\",\n",
    "    data=train_splits[\"eval\"].groupby([\"year\", \"dayofyear\"], as_index=False)[\"total_sales\"].sum(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"total_sales_prediction\",\n",
    "    hue=\"year\",\n",
    "    data=train_splits[\"eval\"].groupby([\"year\", \"dayofyear\"], as_index=False)[\"total_sales_prediction\"].sum(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.distplot(np.minimum(25, np.maximum(-25, train_splits[\"eval\"][\"error\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"eval\"][\"error\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr_plot_by_catid(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.gca(ylim=(-0.5, 0.5), xlim=(0, 25))\n",
    "    autocorrelation_plot(df.groupby([\"date\"])[\"error\"].mean().sort_index(), ax=ax)\n",
    "    plt.title(df.cat_id.unique())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr_plot_by_store(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.gca(ylim=(-0.5, 0.5), xlim=(0, 25))\n",
    "    autocorrelation_plot(df.groupby([\"date\"])[\"error\"].mean().sort_index(), ax=ax)\n",
    "    plt.title(df.store_id.unique())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"eval\"].groupby([\"cat_id\"]).apply(lambda x: autocorr_plot_by_catid(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"eval\"].groupby([\"store_id\"]).apply(lambda x: autocorr_plot_by_store(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "autocorrelation_plot(train_splits[\"eval\"].groupby([\"date\"])[\"error\"].mean().sort_index())\n",
    "plt.ylim((-0.25,0.25))\n",
    "plt.xlim((0,25))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"error\",\n",
    "    hue=\"year\",\n",
    "    data=train_splits[\"eval\"].groupby([\"year\", \"dayofyear\"], as_index=False)[\"error\"].mean(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"error\",\n",
    "    hue=\"year\",\n",
    "    row=\"cat_id\",\n",
    "    data=train_splits[\"eval\"].groupby([\"year\", \"dayofyear\", \"cat_id\"], as_index=False)[\"error\"].mean(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"abs_error\",\n",
    "    hue=\"year\",\n",
    "    data=train_splits[\"eval\"].groupby([\"year\", \"dayofyear\"], as_index=False)[\"abs_error\"].mean(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train day by day models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_ahead in range(1, 28+1):\n",
    "    trial = {\n",
    "        \"features\": (\n",
    "            [\n",
    "                \"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\",\n",
    "                \"cat_id\", \"item_id\", \"store_id\", \"state_id\", \"snap\",\n",
    "                \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\",\n",
    "            ]\n",
    "            + [f\"sales_lag{lag+days_ahead}_win{win}\" for lag in (0, 7, 14, 28) for win in (7, 30, 121, 365)]\n",
    "            + [f\"sales_lag{lag+days_ahead}\" for lag in (0, 7, 14, 28)]\n",
    "            + [f\"sell_price_lag{lag}_win{win}\" for lag in (0, 7, 14, 28) for win in (7, 30, 121, 365)]\n",
    "            + [f\"sell_price_lag{lag}\" for lag in (0, 7, 14, 28)]\n",
    "        ),\n",
    "        \"cat_features\": [\n",
    "            \"dept_id\", \"cat_id\", \"item_id\", \"store_id\", \"state_id\", \"wday\",\n",
    "            \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\",\n",
    "        ],\n",
    "        \"model_params\": dict(\n",
    "            iterations=1000,\n",
    "            boosting_type=\"Plain\",\n",
    "            loss_function=\"Tweedie:variance_power=1.1\",\n",
    "        ),\n",
    "        \"fit_params\": dict(\n",
    "            use_best_model=True,\n",
    "            plot=True,\n",
    "            metric_period=50,\n",
    "        ),\n",
    "        \"subsample\": 0.01,\n",
    "    }\n",
    "    \n",
    "    train_pool, eval_pool, test_pool = generate_training_pools(train_splits, trial)\n",
    "    \n",
    "    model = CatBoostRegressor(**trial[\"model_params\"])\n",
    "    model.fit(train_pool, eval_set=eval_pool, **trial[\"fit_params\"])\n",
    "    models[days_ahead] = model\n",
    "    \n",
    "    train_splits[\"eval\"] = score_data(train_splits[\"eval\"], model, trial)\n",
    "    trial[\"eval_score\"] = r2_score(\n",
    "        train_splits[\"eval\"][\"sales\"],\n",
    "        train_splits[\"eval\"][\"prediction\"],\n",
    "        sample_weight=train_splits[\"eval\"][\"sell_price\"]\n",
    "    )\n",
    "\n",
    "    print(f\"Eval score for day {days_ahead}: {trial['eval_score']}\")\n",
    "    \n",
    "    predictions = model.predict(generate_pool(train_splits[\"forecast\"], trial, subsample=False))\n",
    "    train_splits[\"forecast\"][\"sales\"] = np.where(\n",
    "        train_splits[\"forecast\"][\"day\"] == 1913 + days_ahead,\n",
    "        predictions,\n",
    "        train_splits[\"forecast\"][\"sales\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"forecast\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"forecast\"][\"submission_days_ahead\"] = (train_splits[\"forecast\"][\"day\"] - 1914) % 28 + 1\n",
    "train_splits[\"forecast\"][\"type\"] = (\n",
    "    np.where((train_splits[\"forecast\"][\"day\"]).gt(1913 + 28), \"evaluation\", \"validation\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits[\"forecast\"].groupby([\"type\"])[\"day\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_example = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_example.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = (\n",
    "    train_splits[\"forecast\"]\n",
    "    .assign(f=lambda x: \"F\" + x[\"submission_days_ahead\"].astype(str))\n",
    "    .assign(id=lambda x: x[\"item_id\"].astype(str) + \"_\" + x[\"store_id\"].astype(str) + \"_\" + x[\"type\"])\n",
    "    .pivot(index=\"id\", values=\"sales\", columns=\"f\")[[f\"F{i+1}\" for i in range(28)]]\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "submission.to_csv(\"data/submission.csv\", index=False)\n",
    "submission.to_csv(f\"data/submission_{current_time}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-m5",
   "language": "python",
   "name": "conda-env-kaggle-m5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
