{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df = pd.read_csv(\"data/calendar.csv\", low_memory=False)\n",
    "sales_df = pd.read_csv(\"data/sales_train_validation.csv\", low_memory=False)\n",
    "prices_df = pd.read_csv(\"data/sell_prices.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df = (\n",
    "    sales_df\n",
    "#     .sample(frac=0.2)\n",
    "    .melt(\n",
    "        id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "        var_name=\"d\",\n",
    "        value_name=\"sales\"\n",
    "    )\n",
    "    .merge(calendar_df, on=[\"d\"])\n",
    "    .merge(prices_df, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n",
    "    .assign(total_sales=lambda x: x[\"sales\"] * x[\"sell_price\"])\n",
    "    .assign(day=lambda x: x[\"d\"].str.slice(start=2).astype(int))\n",
    "    .assign(date=lambda x: dd.to_datetime(x[\"date\"]))\n",
    "    .assign(dayofyear=lambda x: x[\"date\"].dt.dayofyear)\n",
    "    .assign(dayofmonth=lambda x: x[\"date\"].dt.day)\n",
    "    .drop(columns=[\"d\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "- are there missing rows in the time series from when the product was not sold?\n",
    "- are there missing or zero-valued prices?\n",
    "- is the data zero-inflated?\n",
    "- how to incorporate events?\n",
    "- how to incorporate time series trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df.describe(percentiles=[0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df.select_dtypes(exclude=[\"number\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(sales_denorm_df, train_size=0.5)\n",
    "val_df, test_df = train_test_split(val_df, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pool = Pool(\n",
    "    data=sales_denorm_df[[\"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\", \"item_id\", \"store_id\", \"sell_price\"]], \n",
    "    label=sales_denorm_df[\"sales\"],\n",
    "    weight=sales_denorm_df[\"sell_price\"],\n",
    "    cat_features=[\"dept_id\", \"store_id\", \"item_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=train_df[[\"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\", \"item_id\", \"store_id\", \"sell_price\"]], \n",
    "    label=train_df[\"sales\"],\n",
    "    weight=train_df[\"sell_price\"],\n",
    "    cat_features=[\"dept_id\", \"store_id\", \"item_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pool = Pool(\n",
    "    data=val_df[[\"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\", \"item_id\", \"store_id\", \"sell_price\"]], \n",
    "    label=val_df[\"sales\"],\n",
    "    weight=val_df[\"sell_price\"],\n",
    "    cat_features=[\"dept_id\", \"store_id\", \"item_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool = Pool(\n",
    "    data=test_df[[\"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\", \"item_id\", \"store_id\", \"sell_price\"]], \n",
    "    label=test_df[\"sales\"],\n",
    "    weight=test_df[\"sell_price\"],\n",
    "    cat_features=[\"dept_id\", \"store_id\", \"item_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=eval_pool,\n",
    "    use_best_model=True,\n",
    "    plot=True,\n",
    "    early_stopping_rounds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "model.save_model(\"data/model.cbm\", pool=train_pool)\n",
    "model.save_model(f\"data/model_{current_time}.cbm\", pool=train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Train score: {model.score(train_pool)}, \"\n",
    "    f\"Eval score: {model.score(eval_pool)}, \"\n",
    "    f\"Test score: {model.score(test_pool)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df[\"prediction\"] = model.predict(complete_pool)\n",
    "\n",
    "sales_denorm_df[\"total_sales_prediction\"] = (\n",
    "    sales_denorm_df[\"prediction\"] * sales_denorm_df[\"sell_price\"]\n",
    ")\n",
    "\n",
    "sales_denorm_df[\"error\"] = (\n",
    "    sales_denorm_df[\"total_sales_prediction\"] - sales_denorm_df[\"total_sales\"]\n",
    ")\n",
    "\n",
    "sales_denorm_df[\"abs_error\"] = abs(\n",
    "    sales_denorm_df[\"total_sales_prediction\"] - sales_denorm_df[\"total_sales\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"total_sales\",\n",
    "    hue=\"year\",\n",
    "    data=sales_denorm_df.groupby([\"year\", \"dayofyear\"], as_index=False)[\"total_sales\"].sum(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"total_sales_prediction\",\n",
    "    hue=\"year\",\n",
    "    data=sales_denorm_df.groupby([\"year\", \"dayofyear\"], as_index=False)[\"total_sales_prediction\"].sum(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.distplot(np.minimum(25, np.maximum(-25, sales_denorm_df[\"error\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df[\"error\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr_plot(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.gca(ylim=(-0.25, 0.25), xlim=(0, 25))\n",
    "    autocorrelation_plot(df.groupby([\"date\"])[\"error\"].mean().sort_index(), ax=ax)\n",
    "    plt.title(df.cat_id.unique())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_denorm_df.groupby([\"cat_id\"]).apply(lambda x: autocorr_plot(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "autocorrelation_plot(sales_denorm_df.groupby([\"date\"])[\"error\"].mean().sort_index())\n",
    "plt.ylim((-0.25,0.25))\n",
    "plt.xlim((0,25))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"error\",\n",
    "    hue=\"year\",\n",
    "    data=sales_denorm_df.groupby([\"year\", \"dayofyear\"], as_index=False)[\"error\"].mean(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"error\",\n",
    "    hue=\"year\",\n",
    "    row=\"cat_id\",\n",
    "    data=sales_denorm_df.groupby([\"year\", \"dayofyear\", \"cat_id\"], as_index=False)[\"error\"].mean(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"abs_error\",\n",
    "    hue=\"year\",\n",
    "    data=sales_denorm_df.groupby([\"year\", \"dayofyear\"], as_index=False)[\"abs_error\"].mean(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct input df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_training_date = sales_denorm_df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = sales_df[[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = (\n",
    "    items_df.assign(key=0)\n",
    "    .merge(calendar_df.assign(key=0))\n",
    "    .merge(prices_df, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n",
    "    .assign(day=lambda x: x[\"d\"].str.slice(start=2).astype(int))\n",
    "    .assign(date=lambda x: dd.to_datetime(x[\"date\"]))\n",
    "    .assign(dayofyear=lambda x: x[\"date\"].dt.dayofyear)\n",
    "    .assign(dayofmonth=lambda x: x[\"date\"].dt.day)\n",
    "    .drop(columns=[\"d\", \"key\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[\"is_forecasted\"] = input_df[\"date\"].gt(max_training_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[\"days_ahead\"] = (input_df[\"date\"] - max_training_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[\"submission_days_ahead\"] = np.minimum(input_df[\"days_ahead\"], (input_df[\"days_ahead\"] - 1) % 28 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[\"type\"] = (\n",
    "    np.where(input_df[\"days_ahead\"].ge(29), \"evaluation\", \"validation\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_df.date.unique()), len(input_df.item_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_pool = Pool(\n",
    "    data=input_df[[\"dayofyear\", \"year\", \"month\", \"dayofmonth\", \"wday\", \"dept_id\", \"item_id\", \"store_id\", \"sell_price\"]], \n",
    "    weight=input_df[\"sell_price\"],\n",
    "    cat_features=[\"dept_id\", \"store_id\", \"item_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[\"prediction\"] = model.predict(forecast_pool)\n",
    "\n",
    "input_df[\"total_sales_prediction\"] = (\n",
    "    input_df[\"prediction\"] * input_df[\"sell_price\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"total_sales_prediction\",\n",
    "    hue=\"year\",\n",
    "    style=\"is_forecasted\",\n",
    "    data=input_df.groupby([\"year\", \"dayofyear\", \"is_forecasted\"], as_index=False)[\"total_sales_prediction\"].sum(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"dayofyear\",\n",
    "    y=\"total_sales_prediction\",\n",
    "    hue=\"year\",\n",
    "    data=sales_denorm_df.groupby([\"year\", \"dayofyear\"], as_index=False)[\"total_sales_prediction\"].sum(),\n",
    "    kind=\"line\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct submission dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = (\n",
    "    input_df\n",
    "    .query(\"days_ahead > 0\")\n",
    "    .assign(f=lambda x: \"F\" + x[\"submission_days_ahead\"].astype(str))\n",
    "    .assign(id=lambda x: x[\"item_id\"] + \"_\" + x[\"store_id\"] + \"_\" + x[\"type\"])\n",
    "    .pivot(index=\"id\", values=\"prediction\", columns=\"f\")[[f\"F{i+1}\" for i in range(28)]]\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "submission.to_csv(\"data/submission.csv\", index=False)\n",
    "submission.to_csv(f\"data/submission_{current_time}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kaggle-m5",
   "language": "python",
   "name": "conda_kaggle-m5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
